{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import spyrit.misc.walsh_hadamard as wh\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from spyrit.learning.model_Had_DCAN import *\n",
    "from spyrit.misc.disp import torch2numpy\n",
    "from spyrit.misc.statistics import Cov2Var\n",
    "from spyrit.learning.nets import *\n",
    "\n",
    "from spas import read_metadata, reconstruction_hadamard\n",
    "from spas import ReconstructionParameters, setup_reconstruction, load_noise, reconstruct\n",
    "from spas.noise import noiseClass\n",
    "from spas.visualization import *\n",
    "#from siemens_star_analysis import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Torch device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = wh.walsh2_matrix(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load('./data/zoom_x1_starsector/zoom_x1_starsector_spectraldata.npz')\n",
    "\n",
    "spectral_data = f['spectral_data']\n",
    "\n",
    "metadata, acquisition_metadata, spectrometer_parameters, dmd_parameters = \\\n",
    "    read_metadata('./data/zoom_x1_starsector/zoom_x1_starsector_metadata.json')\n",
    "wavelengths = np.asarray(acquisition_metadata.wavelengths)\n",
    "\n",
    "print(f'Spectral data dimensions: {spectral_data.shape}')\n",
    "print(f'Wavelength range: {wavelengths[0]} - {wavelengths[-1]} nm')\n",
    "\n",
    "print('\\nAcquired data description:')\n",
    "print(f'Light source: {metadata.light_source}')\n",
    "print(f'Object: {metadata.object}')\n",
    "print(f'Filter: {metadata.filter}')\n",
    "print(f'Patterns: {acquisition_metadata.pattern_amount}')\n",
    "print(f'Integration time: {spectrometer_parameters.integration_time_ms} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = reconstruction_hadamard(acquisition_metadata.patterns, 'walsh', H, spectral_data)\n",
    "\n",
    "plt.imshow(np.sum(recon, axis=2), cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./fit_model2.npz')\n",
    "mu = data['mu']\n",
    "sigma = data['sigma']\n",
    "coeff = data['k']\n",
    "noise = noiseClass(mu, sigma, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_bin_GT, wavelengths_bin_recon, bin_width, noise_bin = spectral_binning(spectral_data.T, wavelengths, 530, 730, 1, noise)\n",
    "recon_GT = reconstruction_hadamard(acquisition_metadata.patterns, 'walsh', H, F_bin_GT.T)\n",
    "\n",
    "plt.imshow(recon_GT, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_GT.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(spectral_data, CR):\n",
    "    \n",
    "    # If only one wavelength is considered\n",
    "    if spectral_data.ndim == 1:\n",
    "        torch_img = np.zeros((2*CR))\n",
    "        \n",
    "        pos = spectral_data[0::2][:CR]\n",
    "        neg = spectral_data[1::2][:CR]\n",
    "        \n",
    "        torch_img[0::2] = pos\n",
    "        torch_img[1::2] = neg\n",
    "    \n",
    "    # If spectral_data contains all wavelengths\n",
    "    if spectral_data.ndim == 2:\n",
    "        \n",
    "        torch_img = np.zeros((2*CR, spectral_data.shape[1]))\n",
    "        \n",
    "        pos = spectral_data[0::2][:CR,:]\n",
    "        neg = spectral_data[1::2][:CR,:]\n",
    "        \n",
    "        torch_img[0::2,:] = pos\n",
    "        torch_img[1::2,:] = neg\n",
    "    \n",
    "    return torch_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "CR = 2048\n",
    "net_arch = 0 # Network variant\n",
    "\n",
    "# Intensity distribution\n",
    "N0 = 10000\n",
    "sig = 0.5\n",
    "\n",
    "#- Training parameters\n",
    "num_epochs = 30\n",
    "lr = 1e-3 \n",
    "step_size = 10\n",
    "gamma = 0.5\n",
    "batch_size = 512\n",
    "reg = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = '_N0_{}_M_{}_epo_{}_lr_{}_sss_{}_sdr_{}_bs_{}_reg_{}'.format(\n",
    "           img_size, CR, num_epochs, lr, step_size,\n",
    "           gamma, batch_size, reg)\n",
    "\n",
    "H_network = H / img_size\n",
    "Mean = np.load('./stats/Average_64x64.npy')/img_size\n",
    "Cov  = np.load('./stats/Cov_64x64.npy')/img_size**2\n",
    "\n",
    "model = DenoiCompNet(img_size, CR, Mean, Cov, net_arch, N0, sig, H_network, Cov2Var(Cov))\n",
    "network_path = './models/NET_c0mp_N0_10000.0_sig_0.5_Denoi_N_64_M_2048_epo_30_lr_0.001_sss_10_sdr_0.5_bs_512_reg_1e-07'\n",
    "load_net(network_path, model, device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = subsample(spectral_data, CR).T\n",
    "F_bin, wavelengths_bin_recon, bin_width, noise_bin = spectral_binning(imgs, wavelengths, 530, 730, 1, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ind, = np.where((wavelengths > 530) & \n",
    "                           (wavelengths < 730))\n",
    "lambda_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(1723)*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_fbin = reconstruction_hadamard(acquisition_metadata.patterns[:2*CR], 'walsh', H, F_bin.T)\n",
    "\n",
    "plt.imshow(recon_fbin, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_img = torch.from_numpy(F_bin)\n",
    "torch_img = torch_img.float()\n",
    "torch_img = torch.reshape(torch_img, (1, 1, 2*CR)) # batches, channels, patterns\n",
    "torch_img = torch_img.to(device)\n",
    "\n",
    "result = (model.forward_reconstruct_expe(\n",
    "    torch_img, 1, 1, img_size, img_size, \n",
    "    torch.from_numpy(noise_bin.mu).float().to(device),\n",
    "    torch.from_numpy(noise_bin.sigma).float().to(device),\n",
    "    torch.from_numpy(noise_bin.K).float().to(device),\n",
    ") + 1) * N0 /2\n",
    "\n",
    "result = result.cpu().detach().numpy().squeeze()\n",
    "\n",
    "_,N0 = model.forward_preprocess_expe(torch_img, 1, 1, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(result, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_img = torch.from_numpy(F_bin)\n",
    "torch_img = torch_img.float()\n",
    "torch_img = torch.reshape(torch_img, (1, 1, 2*CR)) # batches, channels, patterns\n",
    "torch_img = torch_img.to(device)\n",
    "\n",
    "result = model.forward_reconstruct_pinv(\n",
    "    torch_img, 1, 1, img_size, img_size,\n",
    ")\n",
    "\n",
    "result = (result+1)*model.N0/2\n",
    "result = result.cpu().detach().numpy().squeeze()\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(result, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.imshow(result - recon_fbin.squeeze(), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_img = torch.from_numpy(F_bin)\n",
    "torch_img = torch_img.float()\n",
    "torch_img = torch.reshape(torch_img, (1, 1, 2*CR)) # batches, channels, patterns\n",
    "torch_img[0,0,:2] = 0\n",
    "torch_img = torch_img.to(device)\n",
    "\n",
    "model.N0 = 9316.7578125\n",
    " \n",
    "result = model.forward_reconstruct(\n",
    "    torch_img, 1, 1, img_size, img_size, \n",
    ")\n",
    "\n",
    "#result = (result+1) * model.N0/2\n",
    "result = result.cpu().detach().numpy().squeeze()\n",
    "\n",
    "plt.imshow(result, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_img = torch.from_numpy(F_bin)\n",
    "torch_img = torch_img.float()\n",
    "torch_img = torch.reshape(torch_img, (1, 1, 2*CR)) # batches, channels, patterns\n",
    "torch_img[0,0,:2] = 0\n",
    "torch_img = torch_img.to(device)\n",
    "\n",
    "model.N0 = 9316.7578125\n",
    " \n",
    "result = model.forward_reconstruct_mmse(\n",
    "    torch_img, 1, 1, img_size, img_size, \n",
    ")\n",
    "\n",
    "#result = (result+1) * model.N0/2\n",
    "result = result.cpu().detach().numpy().squeeze()\n",
    "\n",
    "plt.imshow(result, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.forward_reconstruct_mmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spas22",
   "language": "python",
   "name": "spas22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
