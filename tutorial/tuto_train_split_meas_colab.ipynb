{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openspyrit/spyrit-examples/blob/master/tutorial/tuto_train_split_meas_colab.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial to train a reconstruction network "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial to train a reconstruction network for 2D single-pixel imaging on stl10, for split measurements.\n",
    "\n",
    "Training is performed by a call to *train.py*. Several parameters allow to modify acquisition, network and training (network architecture), optimisation and the use of tensorboard. \n",
    "\n",
    "Currently you can train the following networks by modifying the network architecture variable *arch*: \n",
    "\n",
    "- 'dc-net': Denoised Completion Network (DCNet). \n",
    "- 'pinv-net': Pseudo Inverse Network (PinvNet).\n",
    "- 'upgd': Unrolled proximal gradient descent (UPGD). \n",
    "\n",
    "and the denoising variable *denoi*: \n",
    "- 'cnn': CNN no batch normalization\n",
    "- 'cnnbn': CNN with batch normalization\n",
    "- 'unet': UNet (0.5 M trainable parameters) \n",
    "- 'drunet': DRUNet (high capacity residual UNet that allows training for all noise levels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On colab, choose GPU at *Runtime/Change runtime type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, mount google drive to import modules spyrit modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_colab = True\n",
    "if (mode_colab is True):\n",
    "    # Connect to googledrive\n",
    "    #if 'google.colab' in str(get_ipython()):\n",
    "    # Mount google drive to access files via colab\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    %cd /content/gdrive/MyDrive/\n",
    "\n",
    "    # For the profiler\n",
    "    !pip install -U tensorboard-plugin-profile\n",
    "\n",
    "    # Load the TensorBoard notebook extension\n",
    "    %load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone Spyrit package"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone and install spyrit package if not installed or change to spyrit folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (mode_colab is True):\n",
    "    # Clone and install\n",
    "    !git clone https://github.com/openspyrit/spyrit.git\n",
    "    %cd spyrit\n",
    "    !pip install -e .\n",
    "\n",
    "    # Checkout to ongoing branch\n",
    "    !git fetch --all\n",
    "\n",
    "    # Add paths for modules\n",
    "    import sys\n",
    "    sys.path.append('./spyrit/core')\n",
    "    sys.path.append('./spyrit/misc')\n",
    "    sys.path.append('./spyrit/tutorial')\n",
    "    %cd ..\n",
    "\n",
    "    # Clone Spyrit-examples and checkout to branch tutorials\n",
    "    !git clone https://github.com/openspyrit/spyrit-examples.git\n",
    "    %cd spyrit-examples/tutorials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download covariance matrix. Alternatively install *openspyrit/spas* package:\n",
    "```\n",
    "    spyrit\n",
    "    ├───stat\n",
    "    │   ├───Average_64x64.npy\n",
    "    │   ├───Cov_64x64.npy\n",
    "    ├───spirit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_cov = True\n",
    "if (download_cov is True):\n",
    "    if 'stat' not in os.listdir():\n",
    "        !pip install girder-client\n",
    "        import girder_client\n",
    "\n",
    "        # api Rest url of the warehouse\n",
    "        url='https://pilot-warehouse.creatis.insa-lyon.fr/api/v1'\n",
    "        \n",
    "        # Generate the warehouse client\n",
    "        gc = girder_client.GirderClient(apiUrl=url)\n",
    "\n",
    "        #%% Download the covariance matrix and mean image\n",
    "        data_folder = './stat/'\n",
    "        dataId_list = [\n",
    "                '63935b624d15dd536f0484a5', # for reconstruction (imageNet, 64)\n",
    "                '63935a224d15dd536f048496', # for reconstruction (imageNet, 64)\n",
    "                ]\n",
    "        for dataId in dataId_list:\n",
    "            myfile = gc.getFile(dataId)\n",
    "            gc.downloadFile(dataId, data_folder + myfile['name'])\n",
    "\n",
    "        print(f'Created {data_folder}') \n",
    "        !ls $data_folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose the following parameters:\n",
    "\n",
    "- Acquisition: \n",
    "    - --img_size: Height / width dimension, default=64\n",
    "    - --M: Number of undersampling patterns, default=512\n",
    "    - --subs: Among 'var','rect', default=\"var\"\n",
    "    \n",
    "- Network and training: \n",
    "    - --data: stl10 or imagenet, default=\"stl10\"\n",
    "    - --model_root: Path to model saving files, default='./model/'\n",
    "    - --data_root: Path to the dataset, default=\"./data/\"\n",
    "\n",
    "    - --N0: Mean maximum total number of photons, default=10\n",
    "    - --stat_root: Path to precomputed data, default=\"./stat/\"\n",
    "    - --arch: Choose among 'dc-net','pinv-net', 'upgd', default=\"dc-net\"\n",
    "    - --denoi: Choose among 'cnn','cnnbn', 'unet', default=\"unet\"\n",
    "\n",
    "- Optimisation:\n",
    "    - --num_epochs: Number of training epochs, default=30\n",
    "    - --batch_size: Size of each training batch, default=512\n",
    "    - --reg: Regularisation Parameter, default=1e-7\n",
    "    - --step_size: Scheduler Step Size, default=10\n",
    "    - --gamma: Scheduler Decrease Rate, default=0.5\n",
    "    - --checkpoint_model: Optional path to checkpoint model, default=\"\"\n",
    "    - --checkpoint_interval: Interval between saving model checkpoints, default=0\n",
    "    - Training is done with *Adam* optimizer, *MSELoss*\n",
    "\n",
    "- Tensorboard:\n",
    "    - --tb_path: Relative path for Tensorboard experiment tracking logs, default=False\n",
    "    - --tb_prof: Code profiler with Tensorboard, default=False\n",
    "    - Logging of scalars *train_loss*, *val_loss* and images (dataset example ground-truth and predictions at different epochs).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, data is perturbed by Poisson noise (100 mean photons) and undersampling factor of 4, on stl10 dataset, and training is done with default parameters and using experiment tracking with tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N0 = 100        # ph/pixel max: number of counts\n",
    "img_size = 64   # image size\n",
    "M =  img_size*2 // 4  # Num measurements = subsampled by factor 4\n",
    "data_root = './data/'\n",
    "data = 'stl10'\n",
    "stat_root = './stat'\n",
    "arch = 'dc-net' # Network architecture\n",
    "denoi = 'unet' # Denoiser architecture\n",
    "num_epochs = 30\n",
    "\n",
    "# Tensorboard logs path\n",
    "mode_tb = True\n",
    "if (mode_tb is True):\n",
    "    now = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "    tb_path = f'runs/runs_stdl10_n100_m1024/{now}' \n",
    "else:\n",
    "    tb_path = None\n",
    "    \n",
    "tb_prof = False # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time: 2 min to download stl10, 2 min per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run train.py\n",
    "!python3 train_split_meas.py --N0 $N0 --M $M --data_root $data_root --data $data --stat_root $stat_root --tb_path $tb_path --tb_prof $tb_prof --arch $arch --denoi $denoi --num_epochs $num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that logs are being save under `spyrit-examples/tutorial/runs` (clicking `Files` icon on your left pannel or directyly in your drive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List model\n",
    "!ls -R model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List runs\n",
    "!ls -R runs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can launch tensorboard to visualize tracked metrics and images. Select *SCALARS* or *IMAGES* to visualize losses/metrics and reconstructed images, respectively. More options are available in the top-right corner (CNN weights, profiling). \n",
    "\n",
    "You can launch tensorboard in another notebook *launch_tensorboard_colab.ipynb* during training but it may not always work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard\n",
    "# %tensorboard --logdir $tb_path\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If run twice tensorboard\n",
    "#!lsof -i:6006\n",
    "#!kill -9 17387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close colab session!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to close colab session by deleting the instance at the upper menu *Runtime/Manage sessions/*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
