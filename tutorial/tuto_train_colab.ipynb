{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openspyrit/spyrit-examples/blob/tutorials/tutorial/tuto_train_colab.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial to train a reconstruction network "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial to train a reconstruction network for 2D single-pixel imaging on stl10.\n",
    "\n",
    "Training is performed by a call to *train.py*. Several parameters allow to modify acquisition, network and training (network architecture), optimisation and the use of tensorboard. \n",
    "\n",
    "Currently you can train the following networks by modifying the network architecture variable *arch*: \n",
    "\n",
    "- 'dc-net': Denoised Completion Network (DCNet). \n",
    "- 'pinv-net': Pseudo Inverse Network (PinvNet).\n",
    "- 'upgd': Unrolled proximal gradient descent (UPGD). \n",
    "\n",
    "and the denoising variable *denoi*: \n",
    "- 'cnn': CNN no batch normalization\n",
    "- 'cnnbn': CNN with batch normalization\n",
    "- 'unet': UNet (0.5 M trainable parameters) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set google colab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, mount google drive to import modules spyrit modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_colab = True\n",
    "if (mode_colab is True):\n",
    "    # Connect to googledrive\n",
    "    #if 'google.colab' in str(get_ipython()):\n",
    "    # Mount google drive to access files via colab\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    %cd /content/gdrive/MyDrive/\n",
    "\n",
    "    # For the profiler\n",
    "    !pip install -U tensorboard-plugin-profile\n",
    "\n",
    "    # Load the TensorBoard notebook extension\n",
    "    %load_ext tensorboard\n",
    "else:\n",
    "    # Install tensorboard for pytorch\n",
    "    !pip install tensorboard-pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On colab, choose GPU at *Runtime/Change runtime type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone Spyrit package"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone and install spyrit package if not installed or change to spyrit folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_spyrit = True\n",
    "if (mode_colab is True):\n",
    "    if install_spyrit is True:\n",
    "        # Clone and install\n",
    "        !git clone https://github.com/openspyrit/spyrit.git\n",
    "        %cd spyrit\n",
    "        !pip install -e .\n",
    "\n",
    "        # Checkout to ongoing branch\n",
    "        !git fetch --all\n",
    "    else:\n",
    "        # cd to spyrit folder is already cloned in your drive\n",
    "        %cd /content/gdrive/MyDrive/Colab_Notebooks/openspyrit/spyrit\n",
    "\n",
    "    # Add paths for modules\n",
    "    import sys\n",
    "    sys.path.append('./spyrit/core')\n",
    "    sys.path.append('./spyrit/misc')\n",
    "    sys.path.append('./spyrit/tutorial')\n",
    "else:\n",
    "    # Change path to spyrit/\n",
    "    os.chdir('../..')\n",
    "    !pwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download covariance matrix. Alternatively install *openspyrit/spas* package:\n",
    "```\n",
    "    spyrit\n",
    "    ├───stat\n",
    "    │   ├───Average_64x64.npy\n",
    "    │   ├───Cov_64x64.npy\n",
    "    ├───spirit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_cov = True\n",
    "if (download_cov is True):\n",
    "    !pip install girder-client\n",
    "    import girder_client\n",
    "\n",
    "    # api Rest url of the warehouse\n",
    "    url='https://pilot-warehouse.creatis.insa-lyon.fr/api/v1'\n",
    "    \n",
    "    # Generate the warehouse client\n",
    "    gc = girder_client.GirderClient(apiUrl=url)\n",
    "\n",
    "    #%% Download the covariance matrix and mean image\n",
    "    data_folder = './stat/'\n",
    "    dataId_list = [\n",
    "            '63935b624d15dd536f0484a5', # for reconstruction (imageNet, 64)\n",
    "            '63935a224d15dd536f048496', # for reconstruction (imageNet, 64)\n",
    "            ]\n",
    "    for dataId in dataId_list:\n",
    "        myfile = gc.getFile(dataId)\n",
    "        gc.downloadFile(dataId, data_folder + myfile['name'])\n",
    "\n",
    "    print(f'Created {data_folder}') \n",
    "    !ls $data_folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose the following parameters:\n",
    "\n",
    "- Acquisition: \n",
    "    - --img_size: Height / width dimension, default=64\n",
    "    - --M: Number of undersampling patterns, default=512\n",
    "    - --subs: Among 'var','rect', default=\"var\"\n",
    "    \n",
    "- Network and training: \n",
    "    - --data: stl10 or imagenet, default=\"stl10\"\n",
    "    - --model_root: Path to model saving files, default='./model/'\n",
    "    - --data_root: Path to the dataset, default=\"./data/\"\n",
    "\n",
    "    - --N0: Mean maximum total number of photons, default=10\n",
    "    - --stat_root: Path to precomputed data, default=\"./stat/\"\n",
    "    - --arch: Choose among 'dc-net','pinv-net', 'upgd', default=\"dc-net\"\n",
    "    - --denoi: Choose among 'cnn','cnnbn', 'unet', default=\"unet\"\n",
    "\n",
    "- Optimisation:\n",
    "    - --num_epochs: Number of training epochs, default=30\n",
    "    - --batch_size: Size of each training batch, default=512\n",
    "    - --reg: Regularisation Parameter, default=1e-7\n",
    "    - --step_size: Scheduler Step Size, default=10\n",
    "    - --gamma: Scheduler Decrease Rate, default=0.5\n",
    "    - --checkpoint_model: Optional path to checkpoint model, default=\"\"\n",
    "    - --checkpoint_interval: Interval between saving model checkpoints, default=0\n",
    "    - Training is done with *Adam* optimizer, *MSELoss*\n",
    "\n",
    "- Tensorboard:\n",
    "    - --tb_path: Relative path for Tensorboard experiment tracking logs, default=False\n",
    "    - --tb_prof: Code profiler with Tensorboard, default=False\n",
    "    - Logging of scalars *train_loss*, *val_loss* and images (dataset example ground-truth and predictions at different epochs).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, data is perturbed by Poisson noise (100 mean photons) and undersampling factor of 4, on stl10 dataset, and training is done with default parameters and using experiment tracking with tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N0 = 100        # ph/pixel max: number of counts\n",
    "img_size = 64   # image size\n",
    "M =  img_size*2 // 4  # Num measurements = subsampled by factor 4\n",
    "data_root = './data/'\n",
    "data = 'stl10'\n",
    "stat_root = './stat'\n",
    "arch = 'dc-net' # Network architecture\n",
    "denoi = 'unet' # Denoiser architecture\n",
    "\n",
    "\n",
    "# Tensorboard logs path\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "tb_path = f'runs/runs_stdl10_n100_m1024/{now}' \n",
    "tb_prof = True # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time: 2 min to download stl10, 2 min per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run train.py\n",
    "if (mode_colab is True):\n",
    "    # Copy tuto_train.py temporarily to main directory to run in colab\n",
    "    !pwd\n",
    "    !cp spyrit/tutorial/train.py .\n",
    "    !python3 train.py --N0 $N0 --M $M --data_root $data_root --data $data --stat_root $stat_root --tb_path $tb_path --tb_prof $tb_prof --arch $arch --denoi $denoi --num_epochs $num_epochs\n",
    "    !rm train.py\n",
    "else:\n",
    "    !python3 spyrit/tutorial/train.py --N0 $N0 --M $M --data_root $data_root --data $data --stat_root $stat_root --tb_path $tb_path --tb_prof $tb_prof --arch $arch --denoi $denoi --num_epochs $num_epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch tensorboard. Select *SCALARS* or *IMAGES*. More options are available in the top-right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard\n",
    "# %tensorboard --logdir $tb_path\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If run twice tensorboard\n",
    "#!lsof -i:6006\n",
    "#!kill -9 17387"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
