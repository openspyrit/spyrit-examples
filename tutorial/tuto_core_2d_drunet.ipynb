{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openspyrit/spyrit-examples/blob/master/tutorial/tuto_core_2d_drunet.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mbA6mRJNlX3Q"
      },
      "source": [
        "# Tutorial 2D - Image reconstruction for single-pixel imaging with DRUNet denoising\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tutorial shows how to simulate data and perform image reconstruction with spyrit toolbox for 2D single-pixel imaging. In specific with DCRUNET that leverages the pretrained DRUNet denoising network.\n",
        "\n",
        "DRUNet taken from https://github.com/cszn/DPIR\n",
        "Deep Plug-and-Play Image Restoration (DPIR) toolbox\n",
        "June 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The image below displays the ground-truth image, undersampled data and reconstruction with different methods.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1bbmk2dHbCQ92_YBO-pXP3qcitv4p3d2U\" alt=\"drawing\" width=\"800\"/>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For **data simulation**, it loads an image from ImageNet and simulated split measurements based on \n",
        "an undersampled Hadamard operator (see [Tutorial on split measurements](https://spyrit.readthedocs.io/en/pinv_cnn/gallery/tuto_acquisition_split_measurements.html#sphx-glr-gallery-tuto-acquisition-split-measurements-py)). You can select the noise level and undersampled factor. \n",
        "\n",
        "**Image reconstruction** is performed using the following methods: \n",
        "-    Pseudo-inverse\n",
        "-    PInvNet:        Linear net (same result as Pseudo-inverse)\n",
        "-    DCNet:          Data completion net with unit matrix denoising\n",
        "-    DCUNet:         Data completion with UNet denoising, trained on stl10 dataset (requires to download UNet weights). \n",
        "-    DCUNetRes:      Data completion with pretrained DRUNet denoising.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set google colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On colab, to run on GPU, select *GPU* from the navigation menu *Runtime/Change runtime type*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BWsO227W3jZ_"
      },
      "source": [
        "Set *mode_colab=True* to run in colab. Mount google drive, needed to import spyrit modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNKXfDpdlX3U"
      },
      "outputs": [],
      "source": [
        "mode_colab = True\n",
        "if (mode_colab is True):\n",
        "    # Connect to googledrive\n",
        "    #if 'google.colab' in str(get_ipython()):\n",
        "    # Mount google drive to access files via colab\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/gdrive\")  \n",
        "    %cd /content/gdrive/MyDrive/    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clone Spyrit package"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JYhnDHEs3tse"
      },
      "source": [
        "Clone and install spyrit package if not installed or move to spyrit folder. \n",
        "\n",
        "Installation set for colab. To run the notebook locally, clone both *spyrit* and *spyrit-examples* at the same level (data files will be downloaded automatically below): \n",
        "\n",
        "```\n",
        "    openspyrit/\n",
        "    ├───spirit\n",
        "    │   ├───stat\n",
        "    │       ├───Average_64x64.npy\n",
        "    │       ├───Cov_64x64.npy\n",
        "    │   ├───spirit\n",
        "    │       ├───model_zoo\n",
        "    │           ├───dc-net_unet_... .pth\n",
        "    │           ├───drunet_gray.pth\n",
        "    ├───spirit-examples\n",
        "    │   ├───tutorial\n",
        "    │       ├───tuto_core_2d_short_drunet.ipynb\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTSdFQCvlX3W"
      },
      "outputs": [],
      "source": [
        "# #%%capture\n",
        "install_spyrit = True\n",
        "if (mode_colab is True):\n",
        "    if install_spyrit is True:\n",
        "        # Clone and install\n",
        "        !git clone https://github.com/openspyrit/spyrit.git\n",
        "        %cd spyrit\n",
        "        !pip install -e .\n",
        "\n",
        "        # Checkout to ongoing branch\n",
        "        !git fetch --all\n",
        "        !pip install girder_client\n",
        "    else:\n",
        "        # cd to spyrit folder is already cloned in your drive\n",
        "        %cd /content/gdrive/MyDrive/Colab_Notebooks/openspyrit/spyrit\n",
        "\n",
        "    # Add paths for modules\n",
        "    import sys\n",
        "    sys.path.append('./spyrit/core')\n",
        "    sys.path.append('./spyrit/misc')\n",
        "    sys.path.append('./spyrit/tutorial')\n",
        "else:\n",
        "    # Change path to spyrit/\n",
        "    # Assumes are in /spyrit-examples/tutorial\n",
        "    import os\n",
        "    os.chdir('../../spyrit')\n",
        "    !pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install extra dependencies\n",
        "!pip install tensorboard\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqfE7ApzlX3X"
      },
      "outputs": [],
      "source": [
        "# Load spyrit modules\n",
        "from spyrit.core.meas import HadamSplit\n",
        "from spyrit.core.noise import NoNoise, Poisson, PoissonApproxGauss\n",
        "from spyrit.core.prep import SplitPoisson\n",
        "from spyrit.core.recon import PseudoInverse, PinvNet, DCNet, DCDRUNet\n",
        "from spyrit.core.nnet import Unet\n",
        "from spyrit.misc.statistics import Cov2Var, data_loaders_stl10, transform_gray_norm\n",
        "from spyrit.misc.disp import imagesc \n",
        "from spyrit.misc.sampling import meas2img2\n",
        "from spyrit.core.train import load_net\n",
        "from spyrit.external.drunet import UNetRes as drunet\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings and requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import gdown\n",
        "import girder_client"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download covariance and DCNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we adopt a full-covariance matrix, which takes into account correlated measurements (see [full covariance](https://spyrit.readthedocs.io/en/pinv_cnn/gallery/tuto_acquisition_split_measurements.html#sphx-glr-gallery-tuto-acquisition-split-measurements-py)). This requires to download the covariance matrix (`download_cov=True`). Alternatively, you can set a unit covariance, which leads to pixelized reconstructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set download data covariance to True for realistic simulations\n",
        "download_cov = True\n",
        "if (download_cov is True):\n",
        "    # api Rest url of the warehouse\n",
        "    url='https://pilot-warehouse.creatis.insa-lyon.fr/api/v1'\n",
        "    \n",
        "    # Generate the warehouse client\n",
        "    gc = girder_client.GirderClient(apiUrl=url)\n",
        "\n",
        "    #%% Download the covariance matrix and mean image\n",
        "    data_folder = './stat/'\n",
        "    dataId_list = [\n",
        "            '63935b624d15dd536f0484a5', # for reconstruction (imageNet, 64)\n",
        "            '63935a224d15dd536f048496', # for reconstruction (imageNet, 64)\n",
        "            ]\n",
        "    for dataId in dataId_list:\n",
        "        myfile = gc.getFile(dataId)\n",
        "        gc.downloadFile(dataId, data_folder + myfile['name'])\n",
        "\n",
        "    print(f'Created {data_folder}') \n",
        "    !ls $data_folder\n",
        "\n",
        "    #%% Download the models\n",
        "    data_folder = './model/'\n",
        "    dataId_list = [\n",
        "                #'644a38c985f48d3da07140ba', # N_rec = 64, M = 4095\n",
        "                '644a38c785f48d3da07140b7', # N_rec = 64, M = 1024\n",
        "                #'644a38c585f48d3da07140b4', # N_rec = 64, M = 512\n",
        "                ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF4uhDERlX3Y"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "H = 64                          # Image height (assumed squared image)\n",
        "M = H**2 // 4                   # Num measurements = subsampled by factor 2\n",
        "B = 10                          # Batch size\n",
        "alpha = 100                     # ph/pixel max: number of counts\n",
        "                                # otherwise, set to unit matrix\n",
        "\n",
        "imgs_path = './spyrit/images'\n",
        "cov_name = './stat/Cov_64x64.npy'\n",
        "\n",
        "# use GPU, if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8WMsSp9clX3Z"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a batch of images from the folder *spyrit/images*. Images are transformed to grayscale and normalized to $[-1,1]$ for training by **transform_gray_norm**. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID3xMtw4lX3Z"
      },
      "outputs": [],
      "source": [
        "# Create a transform for natural images to normalized grayscale image tensors\n",
        "transform = transform_gray_norm(img_size=H)\n",
        "\n",
        "# Create dataset and loader (expects class folder 'images/test/')\n",
        "dataset = torchvision.datasets.ImageFolder(root=imgs_path, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = min(B, len(dataset)))\n",
        "\n",
        "# Select image\n",
        "x0, _ = next(iter(dataloader))\n",
        "x0 = x0[1:6,:,:,:]\n",
        "x = x0.detach().clone()\n",
        "b,c,h,w = x.shape\n",
        "x = x.view(b*c,h*w)\n",
        "print(f'Shape of incoming image (b*c,h*w): {x.shape}')\n",
        "\n",
        "x_plot = x.view(-1,H,H).cpu().numpy()    \n",
        "imagesc(x_plot[0,:,:],'Ground-truth image normalized')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qOSh1COplX3a"
      },
      "source": [
        "## Neural network pipeline and operators"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WXHzhtF4lX3c"
      },
      "source": [
        "### Experimental data simulation: Split measurement, noise and raw measurement operators"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We adopt linear measurements using a Hadamard operator corrupted by Poisson noise."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GB8W8RQzlX3d"
      },
      "source": [
        "Data simulation in spyrit is done by using three operators from using **spyrit.core.meas**: image normalization, split measurements and noise perturbation. In the example below, this corresponds to the following steps:\n",
        "\n",
        "$$\n",
        "x \\xrightarrow[\\text{Step 1}]{\\text{NoNoise}} \\tilde{x}=\\frac{x+1}{2} \\xrightarrow[\\text{Step 2}]{\\text{HadamSplit}} y=P\\tilde{x} \\xrightarrow[\\text{Step 3}]{\\text{Poisson}} \\mathcal{P}(\\alpha y)\n",
        "$$\n",
        "\n",
        "- Step 1: Given an image $x$ between $[-1, 1]$ (for training), the image is first normalized such that $\\tilde{x}$ ranges between $[0, 1]$ as\n",
        "\n",
        "$$\n",
        "\\tilde{x}=\\frac{x+1}{2}\n",
        "$$\n",
        "using **spyrit.core.noise.NoNoise** operator. This normalization is required in order to apply to the forward operator on positive images (see tutorial on [acquisition operators](https://spyrit.readthedocs.io/en/pinv_cnn/gallery/tuto_acquisition_operators.html)).\n",
        "\n",
        "- Step 2: Split measurements $y$ are obtained via the linear operator $P$: \n",
        "\n",
        "$$\n",
        "y = P\\tilde{x} = \n",
        "\\begin{pmatrix}\n",
        "H_{+} \\\\\n",
        "H_{-}\n",
        "\\end{pmatrix}\\tilde{x}=\n",
        "\\begin{pmatrix}\n",
        "\\max(H, 0) \\\\\n",
        "\\max(0,-H)\n",
        "\\end{pmatrix}\\tilde{x}\n",
        "$$\n",
        "\n",
        "where $H=(H_{+}-H_{-})$ is a Hadamard matrix (see [Tutorial on split measurements](https://spyrit.readthedocs.io/en/pinv_cnn/gallery/tuto_acquisition_split_measurements.html#sphx-glr-gallery-tuto-acquisition-split-measurements-py)). \n",
        "\n",
        "- Step 3: Data is finally perturbed by Poisson noise as\n",
        "\n",
        "$$\n",
        "\\tilde{y} = \\mathcal{P}(\\alpha y)\n",
        "$$\n",
        "\n",
        "where $\\alpha$ accounts for the mean photon counts, using spirit's **spyrit.core.noise.Poisson**. \n",
        "\n",
        "In the code below $M$ is the number of meas, $h$ the height, and $Ord$ the Ordering matrix for undersampling. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpV1mA6UlX3d"
      },
      "outputs": [],
      "source": [
        "# Operators \n",
        "#\n",
        "# Order matrix with shape (H, H) used to compute the permutation matrix \n",
        "# (as undersampling taking the first rows only)\n",
        "try:\n",
        "    Cov  = np.load(cov_name)\n",
        "except:\n",
        "    Cov = np.eye(H*H)\n",
        "    print(f\"Cov matrix {cov_name} not found! Set to the identity\")\n",
        "    \n",
        "Ord = Cov2Var(Cov)\n",
        "\n",
        "# Measurement operator: \n",
        "# Computes linear measurements y=Px, where P is a linear operator (matrix) with positive entries      \n",
        "# such that P=[H_{+}; H_{-}]=[max(H,0); max(0,-H)], H=H_{+}-H_{-}\n",
        "meas_op = HadamSplit(M, H, Ord)\n",
        "\n",
        "# Simulates raw split measurements from images in the range [0,1] assuming images provided in range [-1,1]\n",
        "# y=0.5*H(1 + x)\n",
        "# noise = NoNoise(meas_op) # noiseless\n",
        "noise = Poisson(meas_op, alpha)\n",
        "\n",
        "# Simulate raw measurements (non neagative measurements)\n",
        "y = noise(x)\n",
        "print(f'Shape of simulated measurements y: {y.shape}')\n",
        "\n",
        "m_plot = y.numpy()   \n",
        "m_plot = meas2img2(m_plot.T, Ord)\n",
        "m_plot = np.moveaxis(m_plot,-1, 0)\n",
        "print(f'Shape of reshaped simulated measurements y: {m_plot.shape}')\n",
        "\n",
        "imagesc(m_plot[0,:,:],'Simulated Measurement')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SslsO1b_DTnR"
      },
      "source": [
        "Note that measurements are positive, as expected experimentally. \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG2p8DIylX3e"
      },
      "source": [
        "### Preprocessing measurement operator \n",
        "Note that previous steps allow to simulate experimental split measurements, which only considers positive pixels. A fourth step is done in order to preprocess the raw data acquired with a split measurements operator, for an image $\\tilde{x}$, and to compute the measurements for the original $x$  \n",
        "\n",
        "$$\n",
        "y \\xrightarrow[\\text{Step 4}]{\\text{Prep}} \\tilde{m}=\\frac{y_+-y_-}{\\alpha}\\longrightarrow m=\\frac{2\\tilde{m}}{\\alpha}-P\\mathbb{I},\n",
        "$$\n",
        "\n",
        "where $y_+=H_+\\tilde{x}$, which in spyrit is done with **spyrit.core.prep.SplitPoisson**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgT619gSlX3e"
      },
      "outputs": [],
      "source": [
        "# Preprocess the raw data acquired with split measurement operator assuming Poisson noise\n",
        "prep = SplitPoisson(alpha, meas_op)\n",
        "\n",
        "# Preprocessed data\n",
        "m = prep(y)\n",
        "print(f'Shape of preprocessed data m: {m.shape}')\n",
        "\n",
        "\n",
        "m_plot = m.numpy()   \n",
        "m_plot = meas2img2(m_plot.T, Ord)\n",
        "m_plot = np.moveaxis(m_plot,-1, 0)\n",
        "print(f'Shape of reshaped simulated measurements m: {m_plot.shape}')\n",
        "\n",
        "imagesc(m_plot[0,:,:],'Preprocessed data')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GcPslBpQlX3f"
      },
      "source": [
        "### Reconstruction operators"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let $H$ represent the retaining Hadamard patterns, the Hadamard coefficients $m$ are given in terms of the image $x$ as \n",
        "\n",
        "$$\n",
        "m=Hx.\n",
        "$$\n",
        "\n",
        "The Hadamard operator is orthogonal, so an unknown image $\\hat{x}$ can be recovered from the inverse Hadamard transform \n",
        "\n",
        "$$\n",
        "\\hat{x}=H^{\\dagger}m.\n",
        "$$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image reconstruction in spyrit comprises four steps (the last one is optional):\n",
        "\n",
        "1. Denoising\n",
        "\n",
        "2. Data completion\n",
        "\n",
        "3. Hadamard inverse transform\n",
        "\n",
        "4. Nonlinear postprocessing (denoising)\n",
        "\n",
        "$$\n",
        "m\\in\\mathbb{R}^{M} \\xrightarrow[\\text{Denoising}]{\\text{Step 1}} y_1\\in\\mathbb{R}^{M} \\xrightarrow[\\text{Completion}]{\\text{Step 2}} y_2\\in\\mathbb{R}^{N-M} \\xrightarrow[\\text{Inverse}]{\\text{Step 3}} \\hat{x}\\in\\mathbb{R}^{N} \\xrightarrow[\\text{Postprocessing}]{\\text{Step 4}} \\mathcal{D}(\\hat{x})\\in\\mathbb{R}^{N_x\\times N_y}\n",
        "$$\n",
        "\n",
        "with $y=[y_1^T; y_2^T]^T$ and $\\mathcal{D}$ a denoising operator. \n",
        "\n",
        "In spyrit, the four steps are comprised inside **spyrit.core.recon.PinvNet** or **spyrit.core.recon.DCNet**, and are automatically handed for sigle-pixel imaging data. The denoising network in the nonlinear step in dealt by **spyrit.core.nnet.Unet**.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0p_56QDlX3f"
      },
      "outputs": [],
      "source": [
        "# Pseudo-inverse operator\n",
        "pinv = PseudoInverse()\n",
        "\n",
        "# Reconstruction\n",
        "z_pinv = pinv(m, meas_op)\n",
        "print(f'Shape of reconstructed image z: {z_pinv.shape}')\n",
        "\n",
        "z_plot = z_pinv.view(-1,H,H).numpy()\n",
        "imagesc(z_plot[0,:,:],'Pseudo-inverse reconstruction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h2BxcOglX3g"
      },
      "outputs": [],
      "source": [
        "# Pseudo-inverse net\n",
        "\n",
        "# Reconstruction with for Core module (linear net)\n",
        "pinvnet = PinvNet(noise, prep)\n",
        " \n",
        "# use GPU, if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "pinvnet = pinvnet.to(device)\n",
        "\n",
        "x = x0.detach().clone()\n",
        "x = x.to(device)\n",
        "z_pinvnet = pinvnet(x)\n",
        "# z_pinvnet = pinvnet.reconstruct(y)\n",
        "\n",
        "z_plot = z_pinv.view(-1,H,H).numpy()\n",
        "imagesc(z_plot[0,:,:],'Pseudo-inverse reconstruction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mizgTbYlX3g"
      },
      "outputs": [],
      "source": [
        "# DCNet\n",
        "\n",
        "# Reconstruction with for DCNet (linear net + denoising net)\n",
        "dcnet = DCNet(noise, prep, Cov)\n",
        "\n",
        "#y = pinvnet.acquire(x)         # or equivalently here: y = dcnet.acquire(x)\n",
        "#m = pinvnet.meas2img(y)        # zero-padded images (after preprocessing)\n",
        "dcnet = dcnet.to(device)\n",
        "z_dcnet = dcnet.reconstruct(y.to(device))  # reconstruct from raw measurements\n",
        "#x_dcnet_2 = dcnet(x)   # another reconstruction, from the ground-truth image\n",
        "\n",
        "z_plot = z_dcnet.view(-1,H,H).cpu().numpy()\n",
        "imagesc(z_plot[0,:,:],'DCNet reconstruction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pretreined DC UNet (UNet denoising)\n",
        "denoi = Unet()\n",
        "dcnet_unet = DCNet(noise, prep, Cov, denoi)\n",
        "\n",
        "# Load previously trained model\n",
        "try:\n",
        "    # Download weights\n",
        "    url_unet = 'https://drive.google.com/file/d/1LBrjU0B-Tecd4GBRozX9-24LTRzIiMzA/view?usp=drive_link'\n",
        "    model_unet_path = \"./spyrit/model_zoo\"\n",
        "    \n",
        "    if os.path.exists(model_unet_path) is False:\n",
        "        os.mkdir(model_unet_path)\n",
        "        print(f'Created {model_unet_path}')\n",
        "\n",
        "    model_unet_path = os.path.join(model_unet_path, 'dc-net_unet_imagenet_var_N0_10_N_64_M_1024_epo_30_lr_0.001_sss_10_sdr_0.5_bs_256_reg_1e-07_light')\n",
        "    gdown.download(url_unet, f'{model_unet_path}.pth', quiet=False,fuzzy=True)\n",
        "\n",
        "    # Load model    #dcnet_unet.load_state_dict(torch.load(model_path), loa)\n",
        "    load_net(model_unet_path, dcnet_unet, device, False)\n",
        "    \n",
        "    dcnet_unet = dcnet_unet.to(device)\n",
        "    with torch.no_grad():\n",
        "        z_dcunet = dcnet_unet.reconstruct(y.to(device))  # reconstruct from raw measurements\n",
        "\n",
        "    z_plot = z_dcunet.view(-1,H,H).detach().cpu().numpy()\n",
        "    imagesc(z_plot[0,:,:],'DC UNet reconstruction', show=False)\n",
        "except:\n",
        "    print(f'Model {model_unet_path} not found!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DC DRUNET (with pretreined DRUNet denoising)\n",
        "#\n",
        "# Download weights\n",
        "model_drunet_path = './spyrit/model_zoo'\n",
        "url_drunet = 'https://drive.google.com/file/d/1oSsLjPPn6lqtzraFZLZGmwP_5KbPfTES/view?usp=drive_link'\n",
        "\n",
        "if os.path.exists(model_drunet_path) is False:\n",
        "    os.mkdir(model_drunet_path)\n",
        "    print(f'Created {model_drunet_path}')\n",
        "\n",
        "model_drunet_path = os.path.join(model_drunet_path, 'drunet_gray.pth')\n",
        "gdown.download(url_drunet, model_drunet_path, quiet=False,fuzzy=True)\n",
        "\n",
        "# Define denoising network\n",
        "n_channels = 1                   # 1 for grayscale image    \n",
        "denoi_drunet = drunet(in_nc=n_channels+1, out_nc=n_channels, nc=[64, 128, 256, 512], nb=4, act_mode='R',                     \n",
        "            downsample_mode=\"strideconv\", upsample_mode=\"convtranspose\")  \n",
        "\n",
        "# Load pretrained model\n",
        "try:       \n",
        "    denoi_drunet.load_state_dict(torch.load(model_drunet_path), strict=True)       \n",
        "    print(f'Model {model_drunet_path} loaded.')\n",
        "except:\n",
        "    print(f'Model {model_drunet_path} not found!')\n",
        "    load_drunet = False\n",
        "\n",
        "denoi_drunet.eval()         \n",
        "for k, v in denoi_drunet.named_parameters():             \n",
        "    v.requires_grad = False  \n",
        "print(sum(map(lambda x: x.numel(), denoi_drunet.parameters())) )  \n",
        "\n",
        "# Define DCDRUNet\n",
        "#noise_level = 10\n",
        "#dcdrunet = DCDRUNet(noise, prep, Cov, denoi_drunet, noise_level=noise_level)\n",
        "dcdrunet = DCDRUNet(noise, prep, Cov, denoi_drunet)\n",
        "\n",
        "# Reconstruct\n",
        "# Uncomment to set a new noise level: The higher the noise, the higher the denoising\n",
        "noise_level = 10\n",
        "dcdrunet.set_noise_level(noise_level)\n",
        "dcdrunet = dcdrunet.to(device)\n",
        "with torch.no_grad():\n",
        "    # reconstruct from raw measurements\n",
        "    z_dcdrunet = dcdrunet.reconstruct(y.to(device))  \n",
        "\n",
        "denoi_drunet = denoi_drunet.to(device)\n",
        "\n",
        "# DCDRUNet\n",
        "z_plot = z_dcdrunet.view(-1,H,H).detach().cpu().numpy()\n",
        "imagesc(z_plot[0,:,:],f'DC DRUNet reconstruction noise level={noise_level}', show=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "spy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
