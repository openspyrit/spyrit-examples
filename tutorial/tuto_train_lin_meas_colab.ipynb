{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openspyrit/spyrit-examples/blob/tutorials/tutorial/tuto_train_lin_meas_colab.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial to train a reconstruction network "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial to train a reconstruction network for 2D single-pixel imaging on stl10, for linear measurements. In specific, we choose a Hadamard positive matrix, but this can be replaced by any matrix. \n",
    "\n",
    "Training is performed by a call to *train.py*. Several parameters allow to modify acquisition, network and training (network architecture), optimisation and the use of tensorboard. \n",
    "\n",
    "Currently you can train the following networks by modifying the network architecture variable *arch*: \n",
    "\n",
    "- 'dc-net': Denoised Completion Network (DCNet). \n",
    "- 'pinv-net': Pseudo Inverse Network (PinvNet).\n",
    "- 'upgd': Unrolled proximal gradient descent (UPGD). \n",
    "\n",
    "and the denoising variable *denoi*: \n",
    "- 'cnn': CNN no batch normalization\n",
    "- 'cnnbn': CNN with batch normalization\n",
    "- 'unet': UNet (0.5 M trainable parameters) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On colab, choose GPU at *Runtime/Change runtime type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, mount google drive to import modules spyrit modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_colab = True\n",
    "if (mode_colab is True):\n",
    "    # Connect to googledrive\n",
    "    #if 'google.colab' in str(get_ipython()):\n",
    "    # Mount google drive to access files via colab\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    %cd /content/gdrive/MyDrive/\n",
    "\n",
    "    # For the profiler\n",
    "    !pip install -U tensorboard-plugin-profile\n",
    "\n",
    "    # Load the TensorBoard notebook extension\n",
    "    %load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone Spyrit package"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone and install spyrit package if not installed or change to spyrit folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (mode_colab is True):\n",
    "    # Clone and install\n",
    "    !git clone https://github.com/openspyrit/spyrit.git\n",
    "    %cd spyrit\n",
    "    !pip install -e .\n",
    "\n",
    "    # Checkout to ongoing branch\n",
    "    !git fetch --all\n",
    "\n",
    "    # Add paths for modules\n",
    "    import sys\n",
    "    sys.path.append('./spyrit/core')\n",
    "    sys.path.append('./spyrit/misc')\n",
    "    sys.path.append('./spyrit/tutorial')\n",
    "    %cd ..\n",
    "\n",
    "    # Clone Spyrit-examples and checkout to branch tutorials\n",
    "    !git clone https://github.com/openspyrit/spyrit-examples.git\n",
    "    %cd spyrit-examples\n",
    "    !git checkout tutorials\n",
    "    %cd tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose the following parameters:\n",
    "- Measurements type (forward):\n",
    "    - --meas: Measurement operator: 'hadam-split', 'hadam-pos'. Default=\"hadam-split\" \n",
    "    - --noise: Noise operator: 'poisson', 'gauss-approx', 'no-noise'. Default=\"poisson\"\n",
    "    - --prep: Preprocessing operator: 'dir-poisson', 'split-poisson'. Default=\"dir-poisson\"\n",
    "\n",
    "- Acquisition: \n",
    "    - --img_size: Height / width dimension, default=64\n",
    "    - --M: Number of undersampling patterns, default=512\n",
    "    - --subs: Among 'var','rect', default=\"var\"\n",
    "\n",
    "- Network and training: \n",
    "    - --data: stl10 or imagenet, default=\"stl10\"\n",
    "    - --model_root: Path to model saving files, default='./model/'\n",
    "    - --data_root: Path to the dataset, default=\"./data/\"\n",
    "\n",
    "    - --N0: Mean maximum total number of photons, default=10\n",
    "    - --stat_root: Path to precomputed data (cov matrix), default=\"\"\n",
    "    - --arch: Choose among 'dc-net','pinv-net', 'upgd', default=\"dc-net\"\n",
    "    - --denoi: Choose among 'cnn','cnnbn', 'unet', default=\"unet\"\n",
    "\n",
    "- Optimisation:\n",
    "    - --num_epochs: Number of training epochs, default=30\n",
    "    - --batch_size: Size of each training batch, default=512\n",
    "    - --reg: Regularisation Parameter, default=1e-7\n",
    "    - --step_size: Scheduler Step Size, default=10\n",
    "    - --gamma: Scheduler Decrease Rate, default=0.5\n",
    "    - --checkpoint_model: Optional path to checkpoint model, default=\"\"\n",
    "    - --checkpoint_interval: Interval between saving model checkpoints, default=0\n",
    "    - Training is done with *Adam* optimizer, *MSELoss*\n",
    "\n",
    "- Tensorboard:\n",
    "    - --tb_path: Relative path for Tensorboard experiment tracking logs, default=False\n",
    "    - --tb_prof: Code profiler with Tensorboard, default=False\n",
    "    - Logging of scalars *train_loss*, *val_loss* and images (dataset example ground-truth and predictions at different epochs).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we consider noiseless data (1 mean photons) and an undersampling factor of 4. Training is done on stl10 dataset with default parameters and using experiment tracking with tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# (the first three paramaters allow to generalize train_gen_meas.py \n",
    "# to common measurement types)\n",
    "meas = 'hadam-pos'    # measurement type\n",
    "noise = 'no-noise' # noise type\n",
    "prep = 'dir-poisson'    # preprocessing type\n",
    "#\n",
    "N0 = 1.0        # ph/pixel max: number of counts\n",
    "img_size = 64   # image size\n",
    "M =  img_size*2 // 4  # Num measurements = subsampled by factor 4\n",
    "data_root = './data/'\n",
    "data = 'stl10'\n",
    "arch = 'pinv-net' # Network architecture\n",
    "denoi = 'cnn' # Denoiser architecture\n",
    "num_epochs = 30\n",
    "\n",
    "# Tensorboard logs path\n",
    "name_run = \"stdl10_hadampos\"\n",
    "mode_tb = True\n",
    "if (mode_tb is True):\n",
    "    now = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "    tb_path = f'runs/runs_{name_run}_n{int(N0)}_m{M}/{now}'\n",
    "else:\n",
    "    tb_path = None\n",
    "    \n",
    "tb_prof = False # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time: \n",
    "- 2 min to download stl10\n",
    "- 2 min per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run train.py\n",
    "#!python3 train_gen_meas.py --meas 'hadam-pos' --noise 'no-noise' --prep 'dir-poisson'--N0 1 --M 1024 --data_root './data/' --data 'stl10' --stat_root '' --tb_path 'runs/hadam-pos_no-noise_1' --arch 'pinv-net' --denoi 'cnn' --num_epochs 30\n",
    "#!python3 train_gen_meas.py --meas $meas --noise $noise --prep $prep --N0 $N0 --M $M --data_root $data_root --data $data --stat_root $stat_root --tb_path $tb_path --tb_prof $tb_prof --arch $arch --denoi $denoi --num_epochs $num_epochs\n",
    "\n",
    "import subprocess\n",
    "subprocess.run(['python3', 'train_gen_meas.py', '--meas', meas, '--noise', noise, '--prep', prep,\n",
    "                '--N0', str(N0), '--M', str(M), \n",
    "                '--arch', arch, '--denoi', denoi, '--num_epochs', str(num_epochs),\n",
    "                '--tb_path', tb_path])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch tensorboard after training. Select *SCALARS* or *IMAGES*. More options are available in the top-right corner. \n",
    "\n",
    "To launch tensorboard during training, you can use the notebook *launch_tensorboard_colab.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard\n",
    "# %tensorboard --logdir $tb_path\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If run twice tensorboard\n",
    "#!lsof -i:6006\n",
    "#!kill -9 17387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -R model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close colab session!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to close colab session by deleting the instance at the upper menu *Runtime/Manage sessions/*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
